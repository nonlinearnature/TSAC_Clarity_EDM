---
title: "Analysis Narrative"
author: "ER Deyle"
date: "3/9/2022"
output:
  word_document: default
  html_document: default
  pdf_document: default
version: '0.1'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(gridExtra)
library(rEDM)
library(forecast)
library(knitr)
```


## Overview

Broadly speaking, the goals of the analysis are to investigate the viability of empirical dynamic modeling for supporting water-quality management of Lake Tahoe, including basic forecasting, forecasting of future management scenarios (e.g. warming), and clarifying mechanistic hypotheses about the drivers of water clarity changes over time.

Conceptually, the steps are:
1.	Test for the presence of low-dimensional deterministic dynamics through non-parametric prediction.
2.	System identification through causal analysis.
3.	Multivariate model building validated by predictive accuracy, aimed at mechanistic understanding.
4.	Analyses with multivariate model(s) such as stability, threshold, and scenario exploration.

There is a simple, more-or-less off-the-shelf recipe for ideal data-sets. It’s not clear yet whether this will be the best path forward with the Tahoe data.

The analysis has consisted of the following phases:

+ 0. Data processing
+ 1. Single-variable forecast analysis
+ 2. Causal analysis of core variables

### Empirical Dynamic Modeling approach

Empirical dynamic modeling is a minimally-assumptive toolbox for predicting and understanding nonlinear systems from time-series data. This may seem like a mouthful, and the methods are best presented graphically through the following three videos.

+ Introduction to attractors and time-series: https://www.youtube.com/watch?v=fevurdpiRYg

+ Single time-series attractor reconstruction: https://www.youtube.com/watch?v=QQwtrWBwxQg

+ Attractor cross-mapping for causal inference: https://www.youtube.com/watch?v=NrFdIz-D2yM

#### Statistical Significance and Null Models

High prediction skill (forecast accuracy) on its own doesn't always indicate meaningful success in ecological and environmental modeling. For example, if you know how many trees there are in a forest today, it's generally quite easy to make a prediction of how many there will be tomorrow (baring a catastrophic event). Generally, a bare minimum for demonstrating meaningful prediction is that the forecast accuracy is better than the "constant predictor" (also called the "naive predictor") that "tomorrow will be the same as today." It's also important to consider seasonality, as predictable seasonal dynamics are easily captured by many many models regardless of their ultimate suitability.

There's a cautionary tale in non-parametric modeling from the folks at Google who set out to make a search-based predictor for influenza outbreaks— GoogleFlu. Without going into detail, the post-mortum on its initial failures revealed that their machine learning had learned mostly just how to predict the time of year based on things like high school basketball and such.


### Data

Of the data products identified prior to this study, we have used a subset for initial investigation with empirical dynamic modeling. There are additional data that may well be suitable for additional analysis, but also other data that do not readily fit directly into EDM analysis, e.g. because they aren't measured frequently enough.

#### Used in Analysis-to-date
+ Secchi depths:
  + LTP – 1967 to 2020 (every ca.13 days);
+ Chlorophyll a:
  + LTP – 1983 to 2020; 0, 2, 5, 10,15, 20, 30, 40, 50 m (UCD) 60, 75, 90, 105 m
+ Nitrate:
  + LTP – 1968 to 2020 (every ca.13 days until 2007, and then monthly; 0, 2, 5, 10,15, 20, 30, 40, 50 m (UCD) 
+ USGS Stream discharge:
  + Upper Truckee River at South Lake Tahoe, CA UT1 10336610 	from 1980
  + Blackwood Creek near Tahoe City, CA BC1 10336660 		from 1974
  + Ward Creek at Hwy 89 near Tahoe Pines, CA WC8 10336676 	from 1972
+ Precipitation:
  + NWS from 1910 daily ppt and aver of max/min temperature at Tahoe City
+ Climate Indices: (https://psl.noaa.gov/data/climateindices/)
  + Nino 3-4 index
  + SOI

#### Still considering for further analysis
+ Secchi depths:
  + MLTP – 1980 to 2020 (UCD) 
+ Near-surface water temperature:
  + LTP -1967 to 2020 every ca. 13 days);
  + MLTP (monthly)- 1969 to 2020 (UCD)
+ Chlorophyll a: 
  + MLPL – 1983 to 2020; 0, 10, 50, 100 m;
+ Cyclotella spp.:
  + LTP – 1968-2020; 5 and 20 m; data gaps (UCD); counts & biovolume
+ Nitrate:
  + MLTP – 1970 to 2020 (monthly); 0, 10, 50 m (plus 100, 150, 200, 250 300, 350, 400, 450 m)
+ THP:
  + LTP – 1996 to 2020; usually 0, 2, 5, 10,15, 20, 30, 40, 50 m (UCD)
  + MLTP – 1996 to 2020; 0, 10, 50 m (UCD) plus 100, 150, 200, 250 300, 350, 400, 450 m
+ Total P:
  + LTP, 2000 to 2020 - 5, 20 and 50 m
  + MLTP, 2000 to 2020, 0, 10, 50 m.
+ TKN: (Particulated/organic N)
  + LTP, 1989-2020, 5, 20 and 50 m 
  + MLTP, 1989-2020, 0, 10, 50 m, 

#### Unlikely to be used directly for EDM analysis
+ Precipitation:
  + NRCS/CCSS
+ Depth of maximum mixing:
  + 1968 to 2020 (UCD) – one value per year.


## Phase 0 - Data Processing

Data are coming from many different sources and reflect many different kinds of measurements. We tried to make simple choices to get everything in good enough correspondence for the data science, while retaining as much information/detail as possible.  In part with taking a "minimal assumptive approach" to understanding and forecasting the dynamics of the lake water quality, we are trying to do the minimal amount of data "cleaning" necessary. While the individual changes between measurements can reflect random variations (instrumentation uncertainty),  if we "smooth" these variations too much, we may end up removing sources of variation that reflect the underlying drivers of water quality. However, it would also be possible to revise these strategies in light of management needs, e.g. if there are particular time-intervals or depths of interest.

### Picking a time interval

A particular issue is that the time-series approach is best suited to observations with a uniform (regular) sampling frequency, but the observations from the lake have not been made at an entirely uniform frequency. In general, we find that observations are made at least once every two-month interval. Consequently, the minimum data processing we thought necessary was to do two-month averaging, (generating a processed time-series with a uniform interval). We also processed the data using a three-month average to entertain that a small amount of increased averaging might lead to better statistical power.

Below, the Secchi depth measurements are shown over the 2-year period from January 1st 1970 to January 1ast 1972 (plus signs) with both the 2-month and 3-month binned averages shown as a continuous black line.

```{r,echo=FALSE,warning=FALSE,message=FALSE}
df_Secchi_LTP <- read_csv("./EDM_Data_Melack/Secchi_LTP.csv")
load("./DATA/PROCESSED/_0 3-month BGC.Rdata")
load("./DATA/PROCESSED/_0 2-month BGC.Rdata")

date_start_plot <- as.Date("1970-01-01")
date_end_plot <- as.Date("1972-01-01")

g_vis_bin_3mo <- df_3mo_BGC_LTP %>%
  ggplot(aes(x=Date)) + 
  geom_step(aes(y=Secchi_Ave)) +
  geom_point(data=df_Secchi_LTP %>% mutate(Date=as.Date(Date_Time_Local)),aes(y=Secchi_Ave),pch=3) +
  xlim(c(date_start_plot,date_end_plot)) +
  labs(title="3-month averaging")

g_vis_bin_2mo <- df_2mo_BGC_LTP %>%
  ggplot(aes(x=Date)) + 
  geom_step(aes(y=Secchi_Ave)) +
  geom_point(data=df_Secchi_LTP %>% mutate(Date=as.Date(Date_Time_Local)),aes(y=Secchi_Ave),pch=3) +
  xlim(c(date_start_plot,date_end_plot)) +
  labs(title="2-month averaging")

gridExtra::grid.arrange(g_vis_bin_3mo,g_vis_bin_2mo,nrow=1)
```

### Depth

Many of the lake variables aren't just sampled across time, but also across depth. We attempted to usefully summarize this information based on existing limnological understanding of the lake. We use a depth-weighted averaging scheme to look at BGC in the "Secchi zone" and the "deep euphotic" zone. In future analysis, there is also information on the "deep deep" zone of the lake (below the deep chlorophyll maximum). We also note that this approach let us address missing values at particular depths on particular days.




### Plots

With this processing we have the follow variables in hand to use for initial EDM analyses:

```{r,include=FALSE}
load("DATA/PROCESSED/_2 CCM input.Rdata")
load("DATA/PROCESSED/_0 2-month BGC.Rdata")
```

```{r,echo=FALSE}
names(head(df_CCM))[-1]
```

```{r,echo=FALSE}
names_BGC <- (intersect(names(df_CCM)[-1],names(df_2mo_BGC_LTP)[-1]))
units_CCM <- c(
  "Secchi_Ave"         = "(m)",
  "Chla_sechi"         = "(ug*L^-1)",
  "Chla_deep_euphotic" = "(ug*L^-1)",
  "NO3_sechi"          = "(ug*L^-1)",
  "NO3_deep_euphotic"  = "(ug*L^-1)", # "ug L^-1 as N"?
  "NINO_34"            = "(degC)",
  "precip"             = '("in")',
  "Q_mean_Blackwood"   = "(ft^3/s)",
  "Q_mean_Upper_Truckee" = "(ft^3/s)",
  "Q_mean_Ward"        = "(ft^3/s)",
  "SOI"                = ""
)

names_other <- sort(setdiff(names(df_CCM)[-1],names(df_2mo_BGC_LTP)[-1]))


g_processed_time_series <- df_CCM %>%
  rename_at(vars(any_of(names(units_CCM))),.funs=list(~paste(.,units_CCM,sep="\n"))) %>%
  pivot_longer(-Date,names_to="name") %>%
  # mutate(name=factor(name,levels=c(names_BGC,names_other))) %>%
  arrange(name,Date) %>%
  mutate(name=str_replace(name,"_mean","")) %>%
  mutate(name=str_replace_all(name,"_","\n")) %>%
  mutate(name=factor(name,levels=unique(name))) %>%
  ggplot(aes(Date,value,color=name)) + 
  geom_line() + 
  facet_grid(name~.,scales="free_y",labeller=label_value) +
  # facet_grid(name~.,scales="free_y",labeller = labeller(name   = as_labeller(var_names, label_parsed))) +
  # facet_grid(name~.,scales="free_y",labeller = labeller(name   = as_labeller(units_CCM, label_parsed))) +
  theme_bw() +
  theme(legend.position = "none")

print(g_processed_time_series)

if(FALSE){
  f_name <- "./FIGURES/ANALYSIS NARRATIVE/Figure 3 - processed time series.pdf"
  pdf(file=f_name,width = 5,height=9)
  
  g_processed_time_series
  
  dev.off()
}
```


```{r,echo=FALSE}
names_BGC <- (intersect(names(df_CCM)[-1],names(df_2mo_BGC_LTP)[-1]))

units_CCM <- c(
  "Secchi_Ave"         = "(m)",
  "Chla_sechi"         = "(ug*L^{-1})",
  "Chla_deep_euphotic" = "(ug*L^{-1})",
  "NO3_sechi"          = "(ug*L^{-1})",
  "NO3_deep_euphotic"  = "(ug*L^{-1})", # "ug L^-1 as N"?
  "NINO_34"            = "(C^o)",
  "precip"             = '("in")',
  "Q_mean_Blackwood"   = "(ft^3/s)",
  "Q_mean_Upper_Truckee" = "(ft^3/s)",
  "Q_mean_Ward"        = "(ft^3/s)",
  "SOI"                = ""
)


g_tseries_secchi <- df_CCM %>%
  ggplot(aes(x=Date)) + 
  geom_line(aes(y=Secchi_Ave)) +
  labs(y="Secchi Depth (m)",title="",x="")

g_tseries_chla <- df_CCM %>%
  select(Date,starts_with("Chla")) %>%
  pivot_longer(-Date,names_to="Depth Zone",values_to = "Chla",names_prefix = "Chla_") %>%
  mutate(`Depth Zone` = str_replace_all(`Depth Zone`,"_"," ")) %>%
  mutate(`Depth Zone` = str_replace_all(`Depth Zone`,"sechi","secchi")) %>%
  
  ggplot(aes(x=Date,y=Chla,color=`Depth Zone`)) +
  geom_line() +
  scale_color_manual(values = c("lightgreen","darkgreen")) +
  labs(y=expression("Chl a"~(mu*g*L^{-1})),x="",title="")

g_tseries_NO3<- df_CCM %>%
  select(Date,starts_with("NO3")) %>%
  pivot_longer(-Date,names_to="Depth Zone",values_to = "NO3",names_prefix = "NO3_") %>%
  mutate(`Depth Zone` = str_replace_all(`Depth Zone`,"_"," ")) %>%
  mutate(`Depth Zone` = str_replace_all(`Depth Zone`,"sechi","secchi")) %>%
  
  ggplot(aes(x=Date,y=NO3,color=`Depth Zone`)) +
  geom_line() +
  scale_color_manual(values = c("goldenrod1","darkorange2")) +
  labs(y=expression("NO"[3]~(mu*g*L^{-1})),x="",title="")

g_tseries_precip <- df_CCM %>%
  ggplot(aes(x=Date)) + 
  geom_line(aes(y=precip)) +
  labs(y="Precipitation (in)",title="",x="")

g_tseries_Q<- df_CCM %>%
  select(Date,starts_with("Q")) %>%
  pivot_longer(-Date,names_to="Stream",values_to = "Q",names_prefix = "Q_mean_") %>%
  mutate(`Stream` = str_replace_all(`Stream`,"_"," ")) %>%
  # mutate(`Depth Zone` = str_replace_all(`Depth Zone`,"sechi","secchi")) %>%
  
  ggplot(aes(x=Date,y=Q,color=`Stream`)) +
  geom_line() +
  scale_color_manual(values = c("navyblue","royalblue1","deepskyblue")) +
  labs(y=expression("Flow"~(ft^3/s)),x="",title="")

g_tseries_indices <- df_CCM %>%
  select(Date,SOI,NINO_34) %>%
  rename("Ni\u00F1o 3-4 Anomoly" = NINO_34,"Southern Oscillation Index" = SOI) %>%
  pivot_longer(-Date,names_to="Name",values_to = "Index") %>%
  ggplot(aes(x=Date,y=Index,color=`Name`)) +
  geom_line() +
  scale_color_manual(values = c("firebrick3","indianred1")) +
  labs(y="Climate Index",title="")


L_g_tseries <- list(g_tseries_secchi + theme_bw(),
                    g_tseries_chla + theme_bw(),
                    g_tseries_NO3 + theme_bw(),
                    g_tseries_precip + theme_bw(),
                    g_tseries_Q + theme_bw(),
                    g_tseries_indices + theme_bw())

g_tseries <- cowplot::plot_grid(plotlist= L_g_tseries,
                            ncol=1,
                            axis="tblr",
                            align="v")
if(FALSE){
  print(g_tseries)
}

if(TRUE){
  f_name <- "./FIGURES/ANALYSIS NARRATIVE/Figure 3 - processed time series.pdf"
  pdf(file=f_name,width = 6,height=9)
  
  print(g_tseries)
  
  dev.off()
}
```



## Phase 1 - Single-Variable Forecast Analysis

Forecasting can be an end unto itself of ecosystem management. However, analysis of the univariate (single-variable) forecast skill can help us distinguish hypotheses about underlying mechanisms in the lake (ala Hsieh et al. 2005), for example, if the lake water quality is simply tracking a climatic driver or shows evidence of internal feedback and cycling. It also serves as a foundation for subsequent causal and quasi-mechanistic modeling in two ways. (1) It provides guidance on parameters for the analysis, like degree of time averaging. In this case, we are entertaining 2 month and 3 month temporal averaging of the core BGC variables. (2) It validates the grounding assumption of CCM analysis, which is that there are low-dimensional attractor dynamics that (at least partially) explain changes in the time series variables.

### "EDM Benchmarks" of Prediction

The fundamental output of univariate EDM analysis we are interested in are measures of forecast skill. In general, we see the biogeochemistry variables have predictable short-term dynamics. The lowest forecast skill is seen for the deep chlorophyll concentration, "Chla_deep_euphotic", which shows simplex forecast skill of about rho = 0.44, which is still highly significant for > 200 data points under the basic "rule of thumb" for Gaussian (bell-curve) statistics.

Data from natural systems (this lake included) rarely follow the simple rules! Slow secular changes over time, seasonal cycling, extreme events, and many other common behaviors don't fit the "Guassian" model. To assess the statistical power and significance, then, it is better to assess significance using null surrogate methods. The idea with surrogates is to generate random data that preserve basic properties of the system, like the seasonal cycle or the long-term trend, but randomize the "rest" of the variation. The particular "how" of generating surrogates generally matches to a hypothesis. We focused on three such "null hypotheses" for the interpretation of our results.

### "Null Hypotheses"

We will replicate the analysis across several variables, using a few tests and statistics to contextualize and interpret the results. (These are how we establish the statistical significance of the methods; is there meaningful prediction skill).

*Null Hypothesis 1*: Prediction skill is due to random chance.

If the prediction skill we see is simply due to random chance, then we should be able to randomly shuffle the sequence of the observations and get similar forecast skills for these surrogate time series as our analysis of the real data.

*Null Hypothesis 2*: Prediction skill is due to serial autocorrelation in the time series.

If the prediction skill we see is simply due to autocorrelation (inertia) of the observations, then we should be able to generate random realization of an AR1 (simple autoregression) process and get similar forecast skills for these surrogate time series as our analysis of the real data.

*Null Hypothesis 3*: Prediction skill is due to seasonal cycling.

If the prediction skill we measure is due to the inherent seasonality of the lake system, then we should be able to randomize the deviations from the long-term seasonal average and get similar forecast skills for these surrogate time series as our analysis of the real data.


### Evidence of Predictable Dynamics

```{r,echo=FALSE}
load(file="_1_FIGURES_all_nulls.Rdata")

print(g_simplex_all_nulls)
print(g_smap_all_nulls)
```

In all cases, prediction skills are well outside of what would be expected for random data with the same distribution of values (i.e. the “shuffle” surrogates). The autocorrelation (inertia to change through time) as well as seasonal patterns in all the time series do create an expectation of prediction, but in general the EDM results appear to lie outside the expected prediction skill of both the “AR” and the “seasonal” null as well.

Overall, there is clear evidence of low-dimensional behavior; i.e. predictable change over time based on a few variables/interactions.


**What does this include**: both effects from the "rules" governing the internal ecology of the lake as well as effects of climate variables that are themselves predictable (e.g. the seasonal cycle).

**What does this not include**: possible predictible effects of climate drivers that themselves are not predictable, i.e. "stochastic drivers".

### Time horizon

*This piece of analysis is incomplete*

Generally, we find that there is substantial long-term forecast skill popular due to the underlying seasonality of the system.

## Phase 2 - Core Causal Analysis

Questions:
 - Which physical/climate drivers show the strongest evidence of effect on lake water quality?
 - Do the climatic drivers have simple or complex effects?
 
For the second question, we can specifically look at lagged statistical relationships and compare them to the nonlinear causal metrics.


### Variables

For the core causal analysis we focused on the immediate biogeochemical variables: Secchi depth, Chlorophyll-a, and Nitrate, as well as USGS stream flow measurements, TROA precipitation measurements, and El Nino indices (SOI, NINO 3-4).

```{r,echo=FALSE}
load("./DATA/PROCESSED/_2 CCM input.Rdata")

names(df_CCM[-1])
```

### Simple (lagged) statistical correlations

The 2-month averaged flow between the three USGS stations (Upper Truckee, Ward Creek, and Blackwood Creek) are highly correlated with each other at 0-lag. This would suggest either aggregating or working with the single most trust-worthy measurement. The Upper Truckee, for example, has a number of missed measurements due to ice (~1460 days). Ward Creek had very few, and so this juncture, we focused on analyzing stream flow just from the Ward Creek gauge.

In the case of the other variables, we expect that physical drivers acting on the lake won't necessarily act instantenously; therefore, it makes sense to look at possible time-lag relationships. For example, below is the "cross-correlation function" (as a function of time lag) between the Ward creek stream-flow, Q_mean_Ward, and the TROA precipitation record at Tahoe City, "precip".

```{r,echo=FALSE,warning=FALSE,message=FALSE,fig.cap = "Time-lagged correlation analysis of streamflow and precipitation. The Pearson correlation coefficient between streamflow and time-lagged precipitation is shown as a function of the time lag. The 2-month increments in time-lag value reflect that these time series have been processed in 2-month increments. The blue dotted lines represent 95% confidence intervals based on standard Gaussian statistics."}
# df_CCM %>% select(var_i,var_j) %>% filter(complete.cases(.))
g <- ggCcf(df_CCM$precip,df_CCM$Q_mean_Ward,lag.max=12) +
  labs(x="Lag (mo)",
       y="Cross-correlation (\u03C1)",
       title=expression(paste("\u03C1(",Q[Ward],"(t),","Precip(t-Lag))"))
       ) + 
  scale_x_continuous(breaks=seq(-12,12,by=6),labels=~paste(.*2)) +
  theme_bw()
print(g)


```

The above shows that the stream-flow (at Ward creek) is most strongly associated not with the present value of precipitation, but the 4-month lag (2 time-steps of 2-month averaged data).


### Nonlinear coupling relationships

We next examine evidence of coupling using the time-series forecasting framework, convergent cross-mapping. While linear correlation is based on if the static value of one variable predicts the other, CCM tests if the sequence of changes in one predicts the other. While this doesn't sound fundamentally different, it can give very different answers— uncovering hidden causal interactions or clarifying ephemeral "mirage" correlations that seem to appear and disappear.

```{r,echo=FALSE,warning=FALSE,message=FALSE}
out_CCM_example <- ccm(df_CCM,target_column = "precip",lib_column = "Secchi_Ave",E=7,lib_sizes=seq(20,160,by=10),tp=-3)

# out_CCM_example %>%
#   ggplot(aes(x=LibSize)) +
#   geom_line(aes(y=`Secchi_Ave:precip`,color="precip -> Secchi")) +
#   geom_line(aes(y=`precip:Secchi_Ave`,color="Secchi -> precip")) +
#   labs(x="L (library size)",y="Cross-map skill (rho)",color="Causal Direction",)

max_corr_pred <- max(abs(ccf(df_CCM$precip,df_CCM$Secchi_Ave)$acf))

out_CCM_example %>%
  ggplot(aes(x=LibSize)) +
  geom_line(aes(y=`Secchi_Ave:precip`),color="tomato") +
  geom_hline(aes(yintercept = max_corr_pred),lty=2) +
  labs(x="L (library size)",y="Cross-map skill (rho)",title="Causation of Precip -> Secchi Depth")
```
Note that both the cross-map skill and linear correlations are quantified usuing Pearson's correlation coefficient for explained variance, and therefore can, at least superficially, be directly compared.

```{r,echo=FALSE,warning=FALSE,message=FALSE,fig.cap="Time-lagged correlation analysis of Seccih depth and streamflow The Pearson correlation coefficient between streamflow and time-lagged precipitation is shown as a function of the time lag. The 2-month increments in time-lag value reflect that these time series have been processed in 2-month increments. The blue dotted lines represent 95% confidence intervals based on standard Gaussian statistics. Note that both positive and negative cross-correlations are of interest."}
# df_CCM %>% select(var_i,var_j) %>% filter(complete.cases(.))
#     g <- ccf(df_CCM$Chla_sechi,df_CCM$Secchi_Ave,
#              main=paste("Chla_sechi","&","Secchi_Ave"),
#              xlab="Lag (2-mo increments)",
#              ylab="Cross-correlation")
# print(g)

# df_CCM %>% select(var_i,var_j) %>% filter(complete.cases(.))
g <- ggCcf(df_CCM$precip,df_CCM$Secchi_Ave,lag.max=12) +
  labs(x="Lag (mo)",
       y="Cross-correlation (\u03C1)",
       title=expression(paste("\u03C1(",Secchi,"(t),","Precip(t-Lag))"))
       ) + 
  scale_x_continuous(breaks=seq(-12,12,by=6),labels=~paste(.*2)) +
  theme_bw()
print(g)

```

While there is a lagged linear relationship between precipitation and secchi depth (Secchi depth recovers ~16% of the variance in precipitation), the dynamic causal method explains greater variance (dynamics of Secchi depth recovers ~28% of the variance in precipitation). At least on its surface, then, there appears to be evidence of a complex coupling between weather and clarity.

### Summary Comparison

```{r,echo=FALSE,warning=FALSE,message=FALSE}
load(file="./RESULTS/_2 lag analysis table.Rdata")

df_lag_analys_BGC_vs_phys %>%
  select(columns,target,rho_ccm,rho_corr) %>%
  rename(var=columns,driver=target) %>%

kable(digits = 2, row.names = NA, col.names = NA, align=c('r','r','c','c'), 
    caption = NULL, format.args = list(), escape = TRUE)
```



### Interpretation

A key need we understand of Lake Tahoe managers is forecasting and understanding impacts of El Nino oscillations on the lake water quality. There are multiple plausible pathways for ENSO to impact water quality. Our goal with causal analysis is to assess not just the net effect but evidence for the importance/balance of individual pathways. That being said, a direct comparison of "rho_ccm" across variables is tricky without additional analysis. The "Nino 3-4" index does show evidence of a causal effect on Secchi depth, despite the prediction skills associated with it being smaller than the more proximate physical drivers (stream-flow and precipitation).

While we don't want to overinterpret the magnitude of "rho" values between variables, as stated above looking at the agreement or disagreement between the "rho_ccm" (nonlinear causal method) and "rho_corr" (traditional statistical method) for a single driver-response pair is potentially useful. We note that the linear correlations between precipitation and Secchi_ave look very similar in magnitude to those between the stream-flow and Sechi_ave. However, the CCM skill ("rho_ccm") is distinctly larger for the stream-flow than precipitation. This same pattern holds for the Chlorophyll-a variables as well.
